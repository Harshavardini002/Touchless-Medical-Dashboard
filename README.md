🩺 Touchless Medical Dashboard using Hand Gestures
  A real-time **touchless medical dashboard** built with Python, Streamlit, and Altair, using **hand gesture recognition** (via MediaPipe) to interact with patient vitals. Designed for healthcare professionals to monitor data in sterile or restricted environments without physical contact.

  ## 🚀 Features
  - Real-time **hand gesture recognition** (1–5 fingers) using computer vision.
  - Live **vital signs monitoring** from synthetic patient data (`patient_vitals.csv`).
  - Interactive **Streamlit dashboard** with:
    - Auto-refresh every 2 seconds.
    - Dynamic card highlighting based on gestures.
    - Chart filtering (e.g., Blood Pressure shows BP_Systolic and BP_Diastolic).
  - Alerts for critical conditions (e.g., Heart Rate > 110).
  - Modular structure for extensibility.

 

  ## 🧠 How It Works
  - `gesture_listener.py` uses **MediaPipe** to detect hand gestures (1–5 fingers).
  - Gestures are mapped to vital signs and written to `hover.json` (e.g., `{"hover": "2"}` for Blood Pressure).
  - The Streamlit dashboard (`app.py`) reads `hover.json` to highlight cards and filter charts.
  - The dashboard auto-refreshes every 2 seconds to update vitals and gesture inputs.
  - Synthetic data is generated by `generate_synthetic_data.py`, including columns like `Heart_Rate`, `Medication` (e.g., “Aspirin 100mg”).

  
  ## ✅ To Do (Future Enhancements)
  - [ ] Implement swipe gestures (e.g., left-to-right to open sidebar).
  - [ ] Add gesture classification testing for accuracy metrics.
  - [ ] Improve gesture detection robustness under varying lighting and angles.
  - [ ] Integrate a backend (Flask/FastAPI) for real-time data.
  - [ ] Deploy on cloud (Streamlit Cloud, Heroku, or Render).

  ## 🧾 Requirements
  ```bash
  pip install streamlit opencv-python mediapipe pandas altair streamlit_autorefresh
  ```

  ## 🚀 Setup
  1. Clone the repository:
     ```bash
     git clone https://github.com/Harshavardini002/Touchless-Medical-Dashboard.git
     cd Touchless-Medical-Dashboard
     ```
  2. Install dependencies:
     ```bash
     pip install -r requirements.txt
     ```
  3. Generate synthetic data:
     ```bash
     python synthetic_data/generate_synthetic_data.py
     ```
  4. Run the dashboard:
     ```bash
     streamlit run streamlit_dashboard/app.py
     ```
  5. Simulate gestures:
     - Edit `gesture_module/hover.json` (e.g., `{"hover": "2"}` for Blood Pressure).
     - Or run `gesture_listener.py` (if implemented) for live gesture detection.

  ## 📜 License
  MIT License (see [LICENSE](LICENSE) for details).

